{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b6a04b",
   "metadata": {},
   "source": [
    "# HuggingFace TimesFM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea3624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard librairy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Librairies\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ML librairies\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937bca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    PatchTSTConfig,\n",
    "    TimesFmModelForPrediction\n",
    ")\n",
    "\n",
    "from transformers import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e560255",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesfm = TimesFmModelForPrediction.from_pretrained(\n",
    "    \"google/timesfm-2.0-500m-pytorch\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1cfca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \n",
      "TimesFmModelForPrediction(\n",
      "  (decoder): TimesFmModel(\n",
      "    (input_ff_layer): TimesFmResidualBlock(\n",
      "      (input_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "      (activation): SiLU()\n",
      "      (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (residual_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "    )\n",
      "    (freq_emb): Embedding(3, 1280)\n",
      "    (layers): ModuleList(\n",
      "      (0-49): 50 x TimesFmDecoderLayer(\n",
      "        (self_attn): TimesFmAttention(\n",
      "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (o_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        )\n",
      "        (mlp): TimesFmMLP(\n",
      "          (gate_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (down_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (layer_norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "        (input_layernorm): TimesFmRMSNorm((1280,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (horizon_ff_layer): TimesFmResidualBlock(\n",
      "    (input_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (activation): SiLU()\n",
      "    (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (residual_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "-----------------------\n",
      "\n",
      "\n",
      "Number of parameters: \n",
      "498.83M\n",
      "\n",
      "-----------------------\n",
      "\n",
      "\n",
      "Config: \n",
      "TimesFmConfig {\n",
      "  \"architectures\": [\n",
      "    \"TimesFmModelForPrediction\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"context_length\": 2048,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"freq_size\": 3,\n",
      "  \"head_dim\": 80,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"horizon_length\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1280,\n",
      "  \"max_timescale\": 10000,\n",
      "  \"min_timescale\": 1,\n",
      "  \"model_type\": \"timesfm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 50,\n",
      "  \"pad_val\": 1123581321.0,\n",
      "  \"patch_length\": 32,\n",
      "  \"quantiles\": [\n",
      "    0.1,\n",
      "    0.2,\n",
      "    0.3,\n",
      "    0.4,\n",
      "    0.5,\n",
      "    0.6,\n",
      "    0.7,\n",
      "    0.8,\n",
      "    0.9\n",
      "  ],\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tolerance\": 1e-06,\n",
      "  \"transformers_version\": \"4.56.0\",\n",
      "  \"use_positional_embedding\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nModel: \\n{timesfm}\")\n",
    "print(\"\\n-----------------------\\n\\n\")\n",
    "print(f\"Number of parameters: \\n{timesfm.num_parameters()/1e6:.2f}M\")\n",
    "print(\"\\n-----------------------\\n\\n\")\n",
    "print(f\"Config: \\n{timesfm.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd589b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Input len: 5\n",
      "Input (first) size: torch.Size([5])\n",
      "-----------------------\n",
      "Output: odict_keys(['last_hidden_state', 'mean_predictions', 'full_predictions'])\n",
      "Output (hidden) size: torch.Size([5, 64, 1280])\n",
      "Output (points) size: torch.Size([5, 128])\n",
      "Output (quantiles) size: torch.Size([5, 128, 10])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = [torch.randn(length).to(torch.bfloat16).to(timesfm.device) for length in [5, 500, 1000, 3000, 10000]]\n",
    "outputs = timesfm(past_values=dummy_input)\n",
    "print(\"-----------------------\")\n",
    "print(f\"Input len: {len(dummy_input)}\")\n",
    "print(f\"Input (first) size: {dummy_input[0].shape}\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"Output: {outputs.keys()}\")\n",
    "print(f\"Output (hidden) size: {outputs['last_hidden_state'].shape}\")\n",
    "print(f\"Output (points) size: {outputs['mean_predictions'].shape}\")\n",
    "print(f\"Output (quantiles) size: {outputs['full_predictions'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354f05e",
   "metadata": {},
   "source": [
    "### Observe each component of the model: input size, output size, number of parameters\n",
    "\n",
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "402308b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder: \n",
      "TimesFmModel(\n",
      "  (input_ff_layer): TimesFmResidualBlock(\n",
      "    (input_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "    (activation): SiLU()\n",
      "    (output_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (residual_layer): Linear(in_features=64, out_features=1280, bias=True)\n",
      "  )\n",
      "  (freq_emb): Embedding(3, 1280)\n",
      "  (layers): ModuleList(\n",
      "    (0-49): 50 x TimesFmDecoderLayer(\n",
      "      (self_attn): TimesFmAttention(\n",
      "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (o_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (mlp): TimesFmMLP(\n",
      "        (gate_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (down_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (layer_norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (input_layernorm): TimesFmRMSNorm((1280,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\n",
      "Number of trainable parameters: \n",
      "493.91M\n",
      "Number of parameters: \n",
      "493.91M\n"
     ]
    }
   ],
   "source": [
    "decoder = timesfm.decoder\n",
    "print(f\"\\nDecoder: \\n{decoder}\")\n",
    "print(\"\\n-----------------------\\n\\n\")\n",
    "print(f\"\\nNumber of trainable parameters: \\n{sum(p.numel() for p in decoder.parameters() if p.requires_grad)/1e6:.2f}M\")\n",
    "print(f\"Number of parameters: \\n{sum(p.numel() for p in decoder.parameters())/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c343273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_for_decoder(raw_timeseries, model, freq_idx=None):\n",
    "    \"\"\"\n",
    "    raw_timeseries: [batch_size, sequence_length]\n",
    "    retourne: [batch_size, num_patches, hidden_size] prêt pour le decoder\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = raw_timeseries.shape\n",
    "    \n",
    "    # 1. Patching\n",
    "    patch_length = model.config.patch_length\n",
    "    num_patches = seq_len // patch_length\n",
    "    \n",
    "    # Reshape en patches\n",
    "    patches = raw_timeseries.reshape(batch_size, num_patches, patch_length)\n",
    "    \n",
    "    # 2. Projection via le input_ff_layer\n",
    "    # Le decoder a son propre input_ff_layer !\n",
    "    projected_patches = model.decoder.input_ff_layer(patches)\n",
    "    \n",
    "    # 3. Ajout du freq_emb si disponible\n",
    "    if hasattr(model.decoder, 'freq_emb') and freq_idx is not None:\n",
    "        freq_embedding = model.decoder.freq_emb(freq_idx)\n",
    "        projected_patches = projected_patches + freq_embedding.unsqueeze(1)\n",
    "    \n",
    "    return projected_patches\n",
    "\n",
    "# Usage :\n",
    "ready_input = prepare_input_for_decoder(\n",
    "    raw_timeseries=your_data,  # [batch, seq_len]\n",
    "    model=model,\n",
    "    freq_idx=torch.tensor([0, 1, 2])  # selon vos données\n",
    ")\n",
    "\n",
    "# Maintenant vous pouvez utiliser le decoder seul\n",
    "decoder_output = model.decoder(ready_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36fd9d53",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dummy_input = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1280\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesfm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m dummy_padding = torch.ones(\u001b[32m8\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m1280\u001b[39m).to(torch.bfloat16).to(timesfm.device)\n\u001b[32m      3\u001b[39m dummy_frequency = torch.tensor(\u001b[32m5\u001b[39m).to(torch.int).to(timesfm.device)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(8, 64, 1280).to(torch.bfloat16).to(timesfm.device)\n",
    "dummy_padding = torch.ones(8, 64, 1280).to(torch.bfloat16).to(timesfm.device)\n",
    "dummy_frequency = torch.tensor(5).to(torch.int).to(timesfm.device)\n",
    "output = decoder(past_values=dummy_input, past_values_padding=dummy_padding, freq=dummy_frequency)\n",
    "print(\"-----------------------\")\n",
    "print(f\"Input size: {dummy_input.shape}\")\n",
    "print(f\"Output size: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8caa3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621839b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1a8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b86ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d88e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24cd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f323558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43170f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c000d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2623309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20d91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Passer la série through le modèle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     outputs = \u001b[43mmodel\u001b[49m.decoder(input_patches)\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# outputs.shape = [batch_size, num_patches, hidden_size=1280]\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Option 1: Moyenne sur tous les patches\u001b[39;00m\n\u001b[32m      8\u001b[39m     series_embedding = outputs.mean(dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size, 1280]\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Passer la série through le modèle\n",
    "    outputs = .decoder(input_patches)\n",
    "    \n",
    "    # outputs.shape = [batch_size, num_patches, hidden_size=1280]\n",
    "    \n",
    "    # Option 1: Moyenne sur tous les patches\n",
    "    series_embedding = outputs.mean(dim=1)  # [batch_size, 1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef340b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054921c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41181f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bdc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66413e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITER-transformers-for-tokamak-timeseries (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
